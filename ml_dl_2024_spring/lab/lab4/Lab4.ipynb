{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4: Sequential Data Modeling (RNN & Transformers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Change directory to where this file is located\n",
    "\"\"\"\n",
    "%cd '/content/drive/...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0\n",
    "!pip install torchtext==0.16.0\n",
    "!pip install portalocker>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdata\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m importlib\u001b[39m.\u001b[39mreload(data)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "sys.path.append('../data/data')\n",
    "from data import prepareData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version: 2.1.0, Device: mps\n",
      "Using torchtext version: 0.16.0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using Pytorch version: {}, Device: {}\".format(torch.__version__, DEVICE))\n",
    "print(\"Using torchtext version: {}\".format(torchtext.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs for Sequential Data\n",
    "\n",
    "### AG News Dataset\n",
    "\n",
    "- News text dataset with **4 classes (news topics)**, single-labeled.\n",
    "    - Word (1), Sports (2), Business (3), Sci/Tech (4)\n",
    "- 120,000 training examples, 7,600 test examples\n",
    "- Details: <a src=\"https://pytorch.org/text/stable/datasets.html#ag-news\">https://pytorch.org/text/stable/datasets.html#ag-news</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = torchtext.datasets.AG_NEWS(root='../data')\n",
    "labels = [_, 'World', 'Sports', 'Business', 'Sci/Tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print the 1st element of the train data. Use the variable \"labels\" to get the label information.\n",
    "\"\"\"\n",
    "y, x = next(iter(train_data))\n",
    "print(labels[y])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in train data: {1, 2, 3, 4}\n",
      "Classes in test data: {1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classes in train data: {set([label for (label, text) in train_data])}\")\n",
    "print(f\"Classes in test data: {set([label for (label, text) in test_data])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Preprocessing\n",
    "\n",
    "- Tokenizer\n",
    "    - Splits the sentence inti lowercase **tokens**\n",
    "    - Exclude **stopwords** (if necessary)\n",
    "        - ex\\) the, of, this, oh, ...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', ',', 'my', 'name', 'is', 'joonseok', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "tokenizer(\"Hi, my name is Joonseok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'mldl1', 'class', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tokenize the sentence with the \"get_tokenizer\" function.\n",
    "\"\"\"\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "sample_sentence = \"I love MLDL1 class!\" # Modify the sample and see what the function does.\n",
    "tokenizer(sample_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vocabulary Encoder\n",
    "    - Represents a token as **integer index**.\n",
    "    - Vocabulary: tokens in train data\n",
    "    - New tokens: replace with \\<unk\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24104, 3, 1300, 951, 21, 0, 0, 764]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text) # yield: returns a generator instead of a list (faster when applying a function to a list)\n",
    "\n",
    "encoder = build_vocab_from_iterator(tokens(train_data), specials=[\"<unk>\"])\n",
    "encoder.set_default_index(encoder[\"<unk>\"])\n",
    "encoder(tokenizer(\"Hi, my name is Joonseok <unk> !\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[282, 2320, 0, 0, 2644, 764]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Encode the tokens with the \"build_vocab_from_iterator\" function.\n",
    "\n",
    "    - Reference: https://pytorch.org/text/stable/vocab.html#build-vocab-from-iterator\n",
    "\"\"\"\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "train_iterator = tokens(train_data)\n",
    "encoder = build_vocab_from_iterator(train_iterator, specials=[\"<unk>\"])\n",
    "encoder.set_default_index(encoder[\"<unk>\"])\n",
    "\n",
    "encoder(tokenizer(\"I love MLDL1 <unk> class !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text preprocessing pipeline\n",
    "    - Tokenizer: input sentence &rarr; tokens\n",
    "    - Encoder: tokens &rarr; integer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: encoder(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing\n",
      "3\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "After preprocessing\n",
      "2\n",
      "[431, 425, 1, 1605, 14838, 113, 66, 2, 848, 13, 27, 14, 27, 15, 50725, 3, 431, 374, 16, 9, 67507, 6, 52258, 3, 42, 4009, 783, 325, 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the processed data of the 1st element in train_data using text pipeline and label_pipeline.\n",
    "\"\"\"\n",
    "\n",
    "text_pipeline = lambda x: encoder(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "print(\"Before preprocessing\")\n",
    "y, x = next(iter(train_data))\n",
    "print(y)\n",
    "print(x)\n",
    "\n",
    "print(\"After preprocessing\")\n",
    "x = text_pipeline(x)\n",
    "y = label_pipeline(y)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Batch Preprocessing\n",
    "\n",
    "- RNN can process <u>input with any length</u>!\n",
    "- However, to pass a **batch of inputs** to RNN, each input in the batch should have the same length to be converted as a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized collate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"), (3, 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.'), (3, \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\"), (3, 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.'), (3, 'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.'), (3, 'Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\\\but stayed near lows for the year as oil prices surged past  #36;46\\\\a barrel, offsetting a positive outlook from computer maker\\\\Dell Inc. (DELL.O)'), (3, \"Money Funds Fell in Latest Week (AP) AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\"), (3, 'Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.')]\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(train_data)\n",
    "sample_batch = []\n",
    "for _ in range(8):\n",
    "    sample_batch.append(next(iterator))\n",
    "\n",
    "print(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 32\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        if processed_text.size(0) >= MAX_LEN:\n",
    "            processed_text = processed_text[:MAX_LEN]\n",
    "        else:\n",
    "            processed_text = torch.cat([processed_text, torch.zeros(MAX_LEN - processed_text.size(0))])\n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.stack(text_list).long()\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Batch** of encoded tokens\n",
    "    - Token length > MAX_LEN\n",
    "        - Cut the tails.\n",
    "    Token length < MAX_LEN\n",
    "        - Zero-pad.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **MAX_LEN** can be\n",
    "    - Pre-defined\n",
    "    - Minimum of each batch\n",
    "    - Maximum of each batch\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " tensor([[  431,   425,     1,  1605, 14838,   113,    66,     2,   848,    13,\n",
       "             27,    14,    27,    15, 50725,     3,   431,   374,    16,     9,\n",
       "          67507,     6, 52258,     3,    42,  4009,   783,   325,     1,     0,\n",
       "              0,     0],\n",
       "         [15874,  1072,   854,  1310,  4250,    13,    27,    14,    27,    15,\n",
       "            929,   797,   320, 15874,    98,     3, 27657,    28,     5,  4459,\n",
       "             11,   564, 52790,     8, 80617,  2125,     7,     2,   525,   241,\n",
       "              3,    28],\n",
       "         [   58,     8,   347,  4582,   151,    16,   738,    13,    27,    14,\n",
       "             27,    15,  2384,   452,    92,  2059, 27360,     2,   347,     8,\n",
       "              2,   738,    11,   271,    42,   240, 51953,    38,     2,   294,\n",
       "            126,   112],\n",
       "         [   70,  7376,    58,  1810,    29,   905,   537,  2846,    13,    27,\n",
       "             14,    27,    15,   838,    39,  4978,    58, 68871,    29,     2,\n",
       "            905,  2846,     7,   537,    70, 58874,   703,     5,   912,  2520,\n",
       "             93, 89171],\n",
       "         [   58,    92,  4379,     4,  3581,   145,     3,  7577,    23, 12282,\n",
       "              4,    36,   347,    13,   105,    14,   105,    15, 90056,    50,\n",
       "             58,    92,     3, 11312,  1732,     8, 13750,  9735,     3,  3593,\n",
       "              5,    23],\n",
       "         [  151,   152,    43,     3,    45,   355,    71,  2280,    13,    27,\n",
       "             14,    27,    15,   151,   789,  1357,   280,    10, 70411,  4433,\n",
       "            355,  2280,    11,     2,    71,    19,    58,    92,  2301,   353,\n",
       "            468, 55934],\n",
       "         [  756,  1207,   439,     7,   307,    85,    13,    31,    14,    31,\n",
       "             15,  1766,     6,     2,   407,    16,     9,   832,   756,   126,\n",
       "           2145,  1207,   439,    24,   468,   108,     1,   782,   139,     7,\n",
       "              2,   307],\n",
       "         [ 1355,  1236,   517, 13945,    38,  1416,    13,  2199,     1,   172,\n",
       "             14,  2199,     1,   172,    15,   832,   124,  5951,   113,     5,\n",
       "           2539,     7,  1232,     3,     8,    23,   571,    11,  2444,  1687,\n",
       "            439,    69]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The collate_batch function below is designed to process AG News dataset. What is the problem of this function?\n",
    "\n",
    "size가 batch는 전부 동일해야 하는데 데이터의 사이즈는 각 다르므로 equal size하게 만들어 줘야 함.\n",
    "\"\"\"\n",
    "\n",
    "###########################\n",
    "MAX_LEN = 32\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "\n",
    "        ###############################\n",
    "        # make every batch equal size #\n",
    "        ###############################\n",
    "\n",
    "        if processed_text.size(0) >= MAX_LEN:\n",
    "            processed_text = processed_text[:MAX_LEN]\n",
    "        else:\n",
    "            processed_text = torch.cat([processed_text, torch.zeros(MAX_LEN - processed_text.size(0))])\n",
    "            \n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.stack(text_list).long()\n",
    "    return label_list, text_list\n",
    "\n",
    "collate_batch(sample_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    tqdm_bar = tqdm(train_loader)\n",
    "\n",
    "    for label, text in tqdm_bar:\n",
    "        text = text.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1, keepdim = True)[1]\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "        optimizer.step()\n",
    "        tqdm_bar.set_description(\"Epoch {} - train loss: {:.6f}\".format(epoch, loss.item()))\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text in tqdm(test_loader):\n",
    "            text = text.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(text)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True) [1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 32])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_data)\n",
    "test_dataset = to_map_style_dataset(test_data)\n",
    "train_Dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "y, x = next(iter(train_Dataloader))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use nn.Embedding() to get embedding vectors of x.\n",
    "\"\"\"\n",
    "\n",
    "vocab_size = len(encoder)\n",
    "emb_size = 64\n",
    "\n",
    "#######################\n",
    "embedding = nn.Embedding(vocab_size, emb_size)\n",
    "embedded_x = embedding(x)\n",
    "#######################\n",
    "print(embedded_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch API: Vanilla RNN\n",
    "\n",
    "<a src='https://pytorch.org/docs/stable/generated/torch.nn.RNN.html'>'https://pytorch.org/docs/stable/generated/torch.nn.RNN.html</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 64, 10)\n",
    "h0 = torch.randn(2, 64, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement RNN layer using given variables.\n",
    "\"\"\"\n",
    "\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "\n",
    "###########################\n",
    "rnn = nn.RNN(\n",
    "    input_size=emb_size,\n",
    "    hidden_size=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    batch_first=True\n",
    ")\n",
    "###########################\n",
    "\n",
    "h_0 = torch.randn(num_layers, BATCH_SIZE, hidden_dim)\n",
    "output, h_n = rnn(embedded_x, h_0)\n",
    "print(output.shape) # -> torch.Size([BATCH_SIZE, seq_len, hidden_dim])\n",
    "print(h_n.shape) # -> torch.Size([1, BATCH_SIZE, hidden_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement TextClassificationModel.\n",
    "\"\"\"\n",
    "class TextClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden, embed, num_class, batch_size):\n",
    "        \"\"\"\n",
    "        - Define self.embedding and self.rnn layer same as in Q(2) and Q(3).\n",
    "        - self.fc layer will be used to map the average of output hidden units to the target classes.\n",
    "        \"\"\"\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        ################################\n",
    "        self.embedding = nn.Embedding(vocab_size, embed)\n",
    "        self.rnn = nn.RNN(input_size = embed, hidden_size=hidden, num_layers=1, nonlinearity='tanh', bias=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, num_class)\n",
    "        ################################\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        1) Get embedded_x using self.embedding layer.\n",
    "        2) Get output hidden units using self.rnn layer.\n",
    "        3) Calculate the average of output hidden layers.\n",
    "        4) Map the average of output hidden layers to the target classes.\n",
    "        \"\"\"\n",
    "        ################################\n",
    "        embed_x = self.embedding(x)\n",
    "        out, h_n = self.rnn(embed_x)\n",
    "        out = torch.mean(out, dim=1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        ################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdce2b0f89a24f5f977b4c9124590538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67f29ca56ac44ed99ab63228d2ba3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (1, 0.011447340461363396, 70.11333333333333, 0.007273229789969168, 83.61842105263158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6623188dcd70409992b490f660e5ca8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a6a90d230548af940a226ebbd915e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (2, 0.005933680584405859, 86.77333333333333, 0.006343153954336518, 85.67105263157895)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2f60b22bff4d00b3a86a06d71a7647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52a068934684db6b29b9ca2dfd944ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (3, 0.005679939291688303, 87.42083333333333, 0.006291553011458171, 85.64473684210526)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b613ebb664745c5b18cd389b3466fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9240206837b4b15aa3a309c6d1fe993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (4, 0.005654195760438839, 87.46, 0.006310545302143223, 85.67105263157895)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcec49e8da3e44a8a3f8ebff11a75263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a319dc175144c91952503a0902e0861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (5, 0.005650984058404962, 87.46583333333334, 0.006300391478365973, 85.6842105263158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0040c072ae409489c6f29ba29c115d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f87246564334b3c883937106ca7a876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (6, 0.005650680286809802, 87.46583333333334, 0.006300517773549808, 85.6842105263158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2d83db45a0481098fdca586d0be0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d3c1667a0f434a8c4fc4aca866a543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (7, 0.005650652291066945, 87.46583333333334, 0.006297598161587589, 85.6842105263158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b838859f47ec4c3aa4992a623ecc1c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2fb78777254f2ca7a62198af9e78ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (8, 0.005650650832615792, 87.46583333333334, 0.006301394701004028, 85.6842105263158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721186beaee24665a94b14240c6ddf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3023e293616b4906a85cf8d5d2150158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (9, 0.005650650793189804, 87.46583333333334, 0.00629421738417525, 85.6842105263158)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfda16ce3494bb9a4dbde129e0a6775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19efd4a455c64ddb8ec9e03c9e34e4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: {}], \tTrain Loss: {:.4f}, \tTrain Accuracy: {:.2f} %, \tValid Loss: {:.4f}, \tValid Accuracy: {:.2f} % \n",
      " (10, 0.005650650782883167, 87.46583333333334, 0.0063026312150453265, 85.6842105263158)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the model and visualize your experiments with TensorBoard (Train/Validation Loss and Accuracy)\n",
    "\"\"\"\n",
    "\n",
    "################################\n",
    "EPOCHS = 10\n",
    "LR = 1\n",
    "BATCH_SIZE = 64\n",
    "num_class = len(set([label for (label, text) in train_data]))\n",
    "vocab_size = len(encoder)\n",
    "emsize = 64\n",
    "hidden_dim = 32\n",
    "################################\n",
    "\n",
    "model = TextClassificationModel(vocab_size, hidden_dim, emsize, num_class, BATCH_SIZE).to(DEVICE)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_data)\n",
    "test_dataset = to_map_style_dataset(test_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "################################\n",
    "writer = SummaryWriter(log_dir=\"./logs\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train(model, train_dataloader, criterion, optimizer, scheduler)\n",
    "    val_loss, val_acc = evaluate(model, valid_dataloader, criterion)\n",
    "    print(\"\\n[EPOCH: {}], \\tTrain Loss: {:.4f}, \\tTrain Accuracy: {:.2f} %, \\tValid Loss: {:.4f}, \\tValid Accuracy: {:.2f} % \\n\", (epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "writer.flush()\n",
    "writer.close()\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 96588), started 1 day, 0:53:56 ago. (Use '!kill 96588' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-80cd05baa6a95909\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-80cd05baa6a95909\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch LSTM\n",
    "\n",
    "- `torch.nn.Embedding, torch.nn.LSTM`[[link]](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "- For simplicity, we'll use single layer LSTM for encoder & decoder.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./img/lstm.png\">\n",
    "</p>\n",
    "\n",
    "- input_size = length of x_t\n",
    "- hidden_size = dim of h_t\n",
    "- Check out `__init__`\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./img/lstm_2.png\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./img/lstm_input.png\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./img/lstm_output.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For simplicity, we'll use single layer LSTM for encoder & decoder.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./img/lstm_3.png\">\n",
    "</p>\n",
    "\n",
    "- c_t-1.shape = c_t.shape\n",
    "- h_t-1.shape = h_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 32, 64])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hidden_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb Cell 43\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m max_length \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(embedded_x\u001b[39m.\u001b[39mshape) \u001b[39m#-> torch.Size([64, 10, 512])\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(hidden_0\u001b[39m.\u001b[39mshape) \u001b[39m#-> torch.Size([1, 64, 256])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(cell_0\u001b[39m.\u001b[39mshape) \u001b[39m#-> torch.Size([1, 64, 256])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sunukkim/workspace/ml_dl/ml_dl_2024_spring/lab/lab4/Lab4.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m lstm \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLSTM(input_size\u001b[39m=\u001b[39memb_dim, hidden_size\u001b[39m=\u001b[39mhid_dim, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_0' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "emb_dim = 512\n",
    "hid_dim = 256\n",
    "max_length = 10\n",
    "\n",
    "print(embedded_x.shape) #-> torch.Size([64, 10, 512])\n",
    "print(hidden_0.shape) #-> torch.Size([1, 64, 256])\n",
    "print(cell_0.shape) #-> torch.Size([1, 64, 256])\n",
    "\n",
    "lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, batch_first=True)\n",
    "hiddens, (hidden, cell) = lstm(embedded_X, (hidden_0, cell_0))\n",
    "\n",
    "print(hiddens.shape) # (A)\n",
    "print(hidden.shape) # (B)\n",
    "print(cell.shape) # (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output contains (h_0, h_1, ..., h_n) \n",
    "    - (L, N, D*Hout)when `batch_first=False`\n",
    "    - **(N, L, D*Hout) when `batch_first=True`**\n",
    "    - Containing the output features (`h_t`)from the last layser of the LSTM, for each t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp38-cp38-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from transformers) (2.32.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp38-cp38-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sunukkim/miniconda3/envs/aiStudy/lib/python3.8/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp38-cp38-macosx_10_9_x86_64.whl (282 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.3/282.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp38-cp38-macosx_10_12_x86_64.whl (393 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.24.6 regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "[About the Dataset]\n",
    "- Translation Task\n",
    "    - French(src) -> English(trg)\n",
    "    - Sequence to Sequence\n",
    "- Language tokens\n",
    "    - src: 4,345 words in our dictionary\n",
    "    - trg: 2,803 words in out dictionary\n",
    "- Set max length to 10\n",
    "- 10,599 pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "TRAIN_RATIO = 0.7 # train dataset ratio, should be a float in (0, 0.8]\n",
    "VALID_RATIO = 0.8 - TRAIN_RATIO\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lang1', 'lang2', 'max_length', 'reverse', 'input_lang', 'output_lang', 'pairs', 'pair')\n"
     ]
    }
   ],
   "source": [
    "print(prepareData.__code__.co_varnames)\n",
    "# ['lang1', 'lang2', 'max_length', 'reverse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslateDataset(Dataset):\n",
    "    def __init__(self, max_length=10, fra2eng=True):\n",
    "\n",
    "        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length = max_length, reverse=fra2eng)\n",
    "        \n",
    "        self.max_length=max_length\n",
    "\n",
    "        self.input_lang.addWord('PAD')\n",
    "        self.output_lang.addWord('PAD')\n",
    "        self.input_lang_pad = self.input_lang.word2index['PAD']\n",
    "        self.output_lang_pad = self.output_lang.word2index['PAD']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        x, y = self._tensorsFromPair(pair)\n",
    "        return x, y\n",
    "    \n",
    "    def _tensorsFromSentence(self, lang, sentence):\n",
    "        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "        indexes.append(EOS_token)\n",
    "        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "    \n",
    "    def _tensorsFromPair(self, pair):\n",
    "        input_tensor = self._tensorsFromSentence(self.input_lang, pair[0])\n",
    "        target_tensor = self._tensorsFromSentence(self.output_lang, pair[1])\n",
    "        return (input_tensor, target_tensor)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        x_batch = []; y_batch = []\n",
    "\n",
    "        for x, y in data:\n",
    "            if x.shape[0] < self.max_length-1:\n",
    "                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n",
    "            elif x.shape[0] > self.max_length-1:\n",
    "                x = x[:self.max_length-1]\n",
    "            if y.shape[0] < self.max_length-1:\n",
    "                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n",
    "            elif y.shape[0] > self.max_length-1:\n",
    "                y = y[:self.max_length-1]\n",
    "\n",
    "            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n",
    "            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n",
    "\n",
    "        return torch.stack(x_batch), torch.stack(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "\n",
      "\n",
      "This is data example\n",
      "['tu travailles dur .', 'you re working hard .']\n",
      "\n",
      "\n",
      "This is dataset_size: 10599\n",
      "train_size: 7419\n",
      "valid_data: 1059\n",
      "test_data: 2121\n"
     ]
    }
   ],
   "source": [
    "dataset = TranslateDataset(max_length=MAX_LENGTH)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"This is data example\")\n",
    "print(random.choice(dataset.pairs))\n",
    "\n",
    "train_size = int(len(dataset)*TRAIN_RATIO)\n",
    "valid_size = int(len(dataset)*VALID_RATIO)\n",
    "train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n",
    "print(\"\\n\")\n",
    "print(f\"This is dataset_size: {len(dataset)}\")\n",
    "print(f\"train_size: {train_size}\")\n",
    "print(f\"valid_data: {valid_size}\")\n",
    "print(f\"test_data: {len(test_data)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiStudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
